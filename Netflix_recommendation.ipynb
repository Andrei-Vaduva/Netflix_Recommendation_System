{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Show Id                          Title  \\\n",
      "0  cc1b6ed9-cf9e-4057-8303-34577fb54477                       (Un)Well   \n",
      "1  e2ef4e91-fb25-42ab-b485-be8e3b23dedb                         #Alive   \n",
      "2  b01b73b7-81f6-47a7-86d8-acb63080d525  #AnneFrank - Parallel Stories   \n",
      "3  b6611af0-f53c-4a08-9ffa-9716dc57eb9c                       #blackAF   \n",
      "4  7f2d4170-bab8-4d75-adc2-197f7124c070               #cats_the_mewvie   \n",
      "\n",
      "                                         Description  \\\n",
      "0  This docuseries takes a deep dive into the luc...   \n",
      "1  As a grisly virus rampages a city, a lone man ...   \n",
      "2  Through her diary, Anne Frank's story is retol...   \n",
      "3  Kenya Barris and his family navigate relations...   \n",
      "4  This pawesome documentary explores how our fel...   \n",
      "\n",
      "                      Director  \\\n",
      "0                          NaN   \n",
      "1                       Cho Il   \n",
      "2  Sabina Fedeli, Anna Migotto   \n",
      "3                          NaN   \n",
      "4             Michael Margolis   \n",
      "\n",
      "                                           Genres  \\\n",
      "0                                      Reality TV   \n",
      "1  Horror Movies, International Movies, Thrillers   \n",
      "2             Documentaries, International Movies   \n",
      "3                                     TV Comedies   \n",
      "4             Documentaries, International Movies   \n",
      "\n",
      "                                                Cast Production Country  \\\n",
      "0                                                NaN      United States   \n",
      "1                           Yoo Ah-in, Park Shin-hye        South Korea   \n",
      "2                        Helen Mirren, Gengher Gatti              Italy   \n",
      "3  Kenya Barris, Rashida Jones, Iman Benson, Genn...      United States   \n",
      "4                                                NaN             Canada   \n",
      "\n",
      "   Release Date Rating  Duration Imdb Score Content Type         Date Added  \n",
      "0        2020.0  TV-MA  1 Season     6.6/10      TV Show                NaN  \n",
      "1        2020.0  TV-MA    99 min     6.2/10        Movie  September 8, 2020  \n",
      "2        2019.0  TV-14    95 min     6.4/10        Movie       July 1, 2020  \n",
      "3        2020.0  TV-MA  1 Season     6.6/10      TV Show                NaN  \n",
      "4        2020.0  TV-14    90 min     5.1/10        Movie   February 5, 2020  \n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv(\"netflixData.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show Id                  0\n",
      "Title                    0\n",
      "Description              0\n",
      "Director              2064\n",
      "Genres                   0\n",
      "Cast                   530\n",
      "Production Country     559\n",
      "Release Date             3\n",
      "Rating                   4\n",
      "Duration                 3\n",
      "Imdb Score             608\n",
      "Content Type             0\n",
      "Date Added            1335\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the number of missing values in each column of the dataset\n",
    "# This helps to identify if there are any columns with missing data that might need to be addressed\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Title  \\\n",
      "0                       (Un)Well   \n",
      "1                         #Alive   \n",
      "2  #AnneFrank - Parallel Stories   \n",
      "3                       #blackAF   \n",
      "4               #cats_the_mewvie   \n",
      "\n",
      "                                         Description Content Type  \\\n",
      "0  This docuseries takes a deep dive into the luc...      TV Show   \n",
      "1  As a grisly virus rampages a city, a lone man ...        Movie   \n",
      "2  Through her diary, Anne Frank's story is retol...        Movie   \n",
      "3  Kenya Barris and his family navigate relations...      TV Show   \n",
      "4  This pawesome documentary explores how our fel...        Movie   \n",
      "\n",
      "                                           Genres  \n",
      "0                                      Reality TV  \n",
      "1  Horror Movies, International Movies, Thrillers  \n",
      "2             Documentaries, International Movies  \n",
      "3                                     TV Comedies  \n",
      "4             Documentaries, International Movies  \n"
     ]
    }
   ],
   "source": [
    "# Select specific columns from the dataset to use for building a machine learning model\n",
    "# The columns selected are \"Title\", \"Description\", \"Content Type\", and \"Genres\"\n",
    "data = data[[\"Title\",\"Description\",\"Content Type\",\"Genres\"]]\n",
    "\n",
    "# Print the first few rows of the modified dataset to verify the selection\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the NaN\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gheorgheandrei.vaduva/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for text processing\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Download the NLTK stopwords dataset\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize the SnowballStemmer for English\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "# Import the stopwords corpus from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Create a set of English stopwords for filtering out common words\n",
    "stopword = set(stopwords.words('english'))\n",
    "\n",
    "# Define a function to clean the text data\n",
    "def clean(text):\n",
    "    # Convert the text to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove text within square brackets\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    \n",
    "    # Remove newline characters\n",
    "    text = re.sub('\\n', '', text)\n",
    "    \n",
    "    # Remove words containing numbers\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # Apply stemming to the words\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # Return the cleaned text\n",
    "    return text\n",
    "\n",
    "# Apply the clean function to the \"Title\" column of the dataset\n",
    "data[\"Title\"] = data[\"Title\"].apply(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3572            planet\n",
      "1457        el cartel \n",
      "5571     unauthor live\n",
      "2990     marvel defend\n",
      "1719                 b\n",
      "3557    ordinari peopl\n",
      "372         angri bird\n",
      "4042            saawan\n",
      "2067        hire woman\n",
      "286           american\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print a sample of the 'Title' column from the dataset to check the titles\n",
    "print(data.Title.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature list from the 'Genres' column of the dataset\n",
    "feature = data[\"Genres\"].astype(str).tolist() \n",
    "\n",
    "# Initialize the TF-IDF Vectorizer with English stop words\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Fit and transform the 'Genres' data into a TF-IDF matrix\n",
    "tfidf_matrix = tfidf.fit_transform(feature)\n",
    "\n",
    "# Compute the cosine similarity between the TF-IDF vectors\n",
    "similarity = cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series with indices from the dataset's 'Title' column\n",
    "indices = pd.Series(data.index, \n",
    "                    index=data['Title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3                          blackaf\n",
      "285                     washington\n",
      "417                 arrest develop\n",
      "434     astronomi club sketch show\n",
      "451    aunti donna big ol hous fun\n",
      "656                      big mouth\n",
      "752                bojack horseman\n",
      "805                   brew brother\n",
      "935                       champion\n",
      "937                  chappell show\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define a function to get Netflix recommendations based on the title\n",
    "def netFlix_recommendation(title, similarity = similarity):\n",
    "    # Get the index of the given title from the indices Series\n",
    "    index = indices[title]\n",
    "    \n",
    "    # Get the similarity scores for the title\n",
    "    similarity_scores = list(enumerate(similarity[index]))\n",
    "    \n",
    "    # Sort the similarity scores in descending order\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Select the top 10 similar titles\n",
    "    similarity_scores = similarity_scores[0:10]\n",
    "    \n",
    "    # Get the indices of these top 10 similar titles\n",
    "    movieindices = [i[0] for i in similarity_scores]\n",
    "    \n",
    "    # Return the titles of the recommended movies\n",
    "    return data['Title'].iloc[movieindices]\n",
    "\n",
    "# Print recommendations for the title \"girlfriend\"\n",
    "print(netFlix_recommendation(\"girlfriend\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_SWay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
